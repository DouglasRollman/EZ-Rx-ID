{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dougl\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dougl\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.1 MB 6.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.6/11.1 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.9/11.1 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.1 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 6.1 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset of 500 pills (with all augmented versions) saved to pill_subset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"rximage_dataV3.csv\")\n",
    "\n",
    "# Drop duplicates based on base_filename to get unique pills\n",
    "unique_pills = df.drop_duplicates(subset=[\"base_filename\"])\n",
    "\n",
    "# Randomly sample 500 unique pills\n",
    "subset_unique_pills = unique_pills.sample(n=500, random_state=42)\n",
    "\n",
    "# Get all augmented images for the selected pills\n",
    "subset_df = df[df[\"base_filename\"].isin(subset_unique_pills[\"base_filename\"])]\n",
    "\n",
    "# Save the subset to a new CSV\n",
    "subset_df.to_csv(\"pill_subset500.csv\", index=False)\n",
    "\n",
    "print(\"Subset of 500 pills (with all augmented versions) saved to pill_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully split into training and testing sets with shared pills!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define paths\n",
    "dataset_path = \"D:/rximage/image/images/split_padded_rotated\"  # Folder where all images are stored\n",
    "output_dir = \"dataset\"  # Output directory for train/test split\n",
    "train_dir = os.path.join(output_dir, \"train\")\n",
    "test_dir = os.path.join(output_dir, \"test\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"pill_subset500.csv\")\n",
    "base_filenames = df[\"base_filename\"].unique()\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Function to copy images into train and test directories\n",
    "def copy_images(pill_set, target_dir):\n",
    "    for base_filename in pill_set:\n",
    "        # Get all images for this base_filename\n",
    "        filename_prefix = df[df[\"base_filename\"] == base_filename][\"new_filename\"].iloc[0]  # Example file\n",
    "        filename_prefix = os.path.splitext(filename_prefix)[0]  # Remove extension\n",
    "        matching_images = glob.glob(os.path.join(dataset_path, f\"{filename_prefix}*.*\"))  # Match all variations\n",
    "\n",
    "        # Split the images into training and testing (80-20 split)\n",
    "        random.shuffle(matching_images)  # Shuffle to ensure randomness\n",
    "        split_idx = int(0.8 * len(matching_images))  # 80% for training, 20% for testing\n",
    "        train_images = matching_images[:split_idx]\n",
    "        test_images = matching_images[split_idx:]\n",
    "\n",
    "        # Create class folder\n",
    "        class_train_dir = os.path.join(target_dir, \"train\", str(base_filename))\n",
    "        class_test_dir = os.path.join(target_dir, \"test\", str(base_filename))\n",
    "        os.makedirs(class_train_dir, exist_ok=True)\n",
    "        os.makedirs(class_test_dir, exist_ok=True)\n",
    "\n",
    "        # Copy images into train/test directories\n",
    "        for img_path in train_images:\n",
    "            if os.path.exists(img_path):\n",
    "                shutil.copy(img_path, os.path.join(class_train_dir, os.path.basename(img_path)))\n",
    "            else:\n",
    "                print(f\"Warning: {img_path} not found!\")\n",
    "\n",
    "        for img_path in test_images:\n",
    "            if os.path.exists(img_path):\n",
    "                shutil.copy(img_path, os.path.join(class_test_dir, os.path.basename(img_path)))\n",
    "            else:\n",
    "                print(f\"Warning: {img_path} not found!\")\n",
    "\n",
    "# Copy images into train and test sets\n",
    "copy_images(base_filenames, output_dir)\n",
    "\n",
    "print(\"Dataset successfully split into training and testing sets with shared pills!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dougl\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dougl\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/10: 100%|██████████| 375/375 [2:14:39<00:00, 21.55s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 4.9014 - Accuracy: 6.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 375/375 [2:05:27<00:00, 20.07s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Loss: 2.0284 - Accuracy: 41.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 375/375 [2:22:02<00:00, 22.73s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Loss: 0.9386 - Accuracy: 70.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 375/375 [3:12:48<00:00, 30.85s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Loss: 0.4886 - Accuracy: 84.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 375/375 [1:43:09<00:00, 16.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Loss: 0.3097 - Accuracy: 90.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 375/375 [1:58:12<00:00, 18.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Loss: 0.2801 - Accuracy: 91.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 375/375 [1:25:47<00:00, 13.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Loss: 0.1912 - Accuracy: 94.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  35%|███▍      | 131/375 [43:57<1:21:53, 20.14s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths to dataset\n",
    "train_dir = \"dataset/train\"\n",
    "test_dir = \"dataset/test\"\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "num_classes = 500  # Since you have 500 different pills\n",
    "\n",
    "# Transformations for data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 (ResNet input size)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Pre-trained ResNet stats\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load the pre-trained ResNet model\n",
    "model = models.resnet18(pretrained=True)  # You can also use resnet34, resnet50, etc.\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)  # Modify the final layer to match the number of classes (50)\n",
    "\n",
    "# Move the model to the GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/len(train_loader):.4f} - Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Optionally, save the model after every epoch\n",
    "    torch.save(model.state_dict(), f\"model_epoch_{epoch+1}.pth\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
